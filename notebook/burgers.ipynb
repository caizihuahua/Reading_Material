{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4799,"status":"ok","timestamp":1657728112307,"user":{"displayName":"Zihua Cai","userId":"13643425498526697447"},"user_tz":-480},"id":"vKs6W4pKSm5g"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.interpolate import griddata\n","import os,time,datetime,sys"]},{"cell_type":"markdown","metadata":{"id":"Lc-zJQR0Sm5j"},"source":["### Structure of the PINNs"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1657728112307,"user":{"displayName":"Zihua Cai","userId":"13643425498526697447"},"user_tz":-480},"id":"1vKspOHtSm5l","outputId":"e5d49090-b0c0-4f1b-a9ea-9b3b02fd37be"},"outputs":[{"name":"stdout","output_type":"stream","text":["python    : 3.7.13 (default, Apr 24 2022, 01:04:09) \n","[GCC 7.5.0]\n","tensorflow: 2.8.2\n","rand seed : 1234\n"]}],"source":["in_dim = 2\n","out_dim = 1\n","width = 20\n","depth = 7\n","\n","epoch = 8000\n","tol = 1e-8\n","\n","N_0 = 50\n","N_b = 50\n","N_r = 2000\n","\n","w_init = \"glorot_normal\"\n","b_init = \"zeros\"\n","act = \"tanh\"\n","\n","lr = tf.keras.optimizers.schedules.CosineDecay(\n","    initial_learning_rate = 5e-3,\n","    decay_steps = epoch,\n","    alpha = 1e-2\n",")\n","\n","opt = \"Adam\"\n","info_freq = 500\n","info_seed = 1234\n","\n","weight_data = 1.\n","weight_pde = 1.\n","\n","print(\"python    :\", sys.version)\n","print(\"tensorflow:\", tf.__version__)\n","print(\"rand seed :\", info_seed)\n","os.environ[\"PYTHONHASHSEED\"] = str(info_seed)\n","np.random.seed(info_seed)\n","tf.random.set_seed(info_seed)"]},{"cell_type":"markdown","metadata":{"id":"kyfD6CJ3Sm5m"},"source":["### Data for Burgers equation\n","\n","$$\n","\\begin{aligned}\n","\u0026u_t+uu_x−(0.01/\\pi)u_{xx}=0,   x\\in[−1,1],   t\\in[0,1] \\\\\n","\u0026u(0,x)=−sin(\\pi x)\\\\\n","\u0026u(t,−1)=u(t,1)=0\n","\\end{aligned}\n","$$"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1657728112308,"user":{"displayName":"Zihua Cai","userId":"13643425498526697447"},"user_tz":-480},"id":"YbBAnuhtSm5n"},"outputs":[],"source":["tmin, tmax =  0., 1.\n","xmin, xmax = -1., 1.\n","lb = tf.constant([tmin, xmin], dtype = tf.float32)\n","ub = tf.constant([tmax, xmax], dtype = tf.float32)\n","\n","t_0 = tf.ones((N_0, 1), dtype = tf.float32) * lb[0]\n","x_0 = tf.random.uniform((N_0, 1), lb[1], ub[1], dtype = tf.float32)\n","t_b = tf.random.uniform((N_b, 1), lb[0], ub[0], dtype = tf.float32)\n","x_b = lb[1] + (ub[1] - lb[1]) * tf.keras.backend.random_bernoulli((N_b, 1), .5, dtype = tf.float32)\n","t_r = tf.random.uniform((N_r, 1), lb[0], ub[0], dtype = tf.float32)\n","x_r = tf.random.uniform((N_r, 1), lb[1], ub[1], dtype = tf.float32)\n","\n","# initial and boundary\n","u_0 = -tf.sin(np.pi*x_0)\n","u_b = tf.zeros((x_b.shape[0],1),dtype=tf.float32)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1657728112308,"user":{"displayName":"Zihua Cai","userId":"13643425498526697447"},"user_tz":-480},"id":"07UvZuTfSm5o"},"outputs":[],"source":["t = tf.concat([t_0,t_b],axis=0)\n","x = tf.concat([x_0,x_b],axis=0)\n","u = tf.concat([u_0,u_b],axis=0)"]},{"cell_type":"markdown","metadata":{"id":"Cw5BhKL0Sm5o"},"source":["### Build PINNs"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":756,"status":"ok","timestamp":1657728113059,"user":{"displayName":"Zihua Cai","userId":"13643425498526697447"},"user_tz":-480},"id":"9oTOu6lpSm5p"},"outputs":[],"source":["class PINN(tf.keras.Model):\n","    def __init__(\n","            self,\n","            t,x,u,t_r,x_r,lb,ub,\n","            in_dim,out_dim,width,depth,\n","            activ=\"tanh\",w_init=\"glorot_normal\",b_init=\"zeros\",\n","            lr=1e-3,opt=\"Adam\",weight_data=1.,weight_pde=1.,\n","            info_freq=100,info_seed=1234):\n","        super().__init__()\n","        # information\n","        self.info_freq = info_freq\n","        self.info_seed = info_freq\n","        # initial the data\n","        self.data_type = tf.float32\n","        self.x = tf.convert_to_tensor(x,dtype=self.data_type)\n","        self.t = tf.convert_to_tensor(t,dtype=self.data_type)\n","        self.u = tf.convert_to_tensor(u,dtype=self.data_type)\n","        self.x_r = tf.convert_to_tensor(x_r,dtype=self.data_type)\n","        self.t_r = tf.convert_to_tensor(t_r,dtype=self.data_type)\n","        self.lb = tf.convert_to_tensor(lb,dtype=self.data_type)\n","        self.ub = tf.convert_to_tensor(ub,dtype=self.data_type)\n","        self.nu = tf.constant(0.01/np.pi,dtype=self.data_type)\n","        # neuron network configuration\n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        self.width = width\n","        self.depth = depth\n","        self.activ = activ\n","        self.w_init = w_init\n","        self.b_init = b_init\n","        self.lr = lr\n","        self.opt = opt\n","        self.weight_data = weight_data\n","        self.weight_pde = weight_pde\n","        \n","        # call\n","        self.dnn = self.dnn_init(in_dim,out_dim,width,depth)\n","        self.params = self.dnn.trainable_variables\n","        self.optimizer = tf.keras.optimizers.Adam(learning_rate = lr, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n","\n","        # track loss\n","        self.ep_log = []\n","        self.loss_log = []\n","\n","        print(\"\u003e\u003e\u003e\u003e\u003e start time:\", datetime.datetime.now())\n","        print(\"\u003e\u003e\u003e\u003e\u003e configuration;\")\n","        print(\"         dtype        :\", self.data_type)\n","        print(\"         activ func   :\", self.activ)\n","        print(\"         weight init  :\", self.w_init)\n","        print(\"         learning rate:\", self.lr)\n","        print(\"         optimizer    :\", self.opt)\n","        print(\"         summary      :\", self.dnn.summary())\n","    \n","    def dnn_init(self,in_dim,out_dim,width,depth):\n","        net = tf.keras.Sequential()\n","        net.add(tf.keras.layers.InputLayer(in_dim))\n","        # net.add(tf.keras.layers.Lambda(lambda x: 2. * (x - self.lb) / (self.ub - self.lb) - 1.))\n","\n","        for l in range(depth - 1):\n","            net.add(tf.keras.layers.Dense(units=width, activation = self.activ,kernel_initializer = self.w_init, bias_initializer = self.b_init, ))\n","        net.add(tf.keras.layers.Dense(out_dim))\n","        return net\n","    \n","    def loss_pde(self):\n","        with tf.GradientTape(persistent=True) as tp:\n","            tp.watch(self.t_r)\n","            tp.watch(self.x_r)\n","            u = self.dnn(tf.concat([self.t_r,self.x_r],1))\n","            u_t = tp.gradient(u,self.t_r)\n","            u_x = tp.gradient(u,self.x_r)\n","        u_xx = tp.gradient(u_x,self.x_r)\n","        del tp\n","        gv = u_t + u * u_x - self.nu * u_xx\n","        r = tf.reduce_mean(tf.square(gv))\n","        return r\n","    \n","    def loss_icbc(self):\n","        u_nn = self.dnn(tf.concat([self.t,self.x],1))\n","        return tf.reduce_mean(tf.square(self.u-u_nn))\n","    \n","    @tf.function\n","    def grad_desc(self):\n","        with tf.GradientTape() as tp:\n","            loss = self.loss_pde() + self.loss_icbc()\n","        grad = tp.gradient(loss,self.params)\n","        del tp\n","        self.optimizer.apply_gradients(zip(grad,self.params))\n","        return loss\n","    \n","    def train(self,epoch,tol):\n","        print(\"\u003e\u003e\u003e\u003e\u003e training setting;\")\n","        print(\"         # of epoch     :\", epoch)\n","        print(\"         convergence tol:\", tol)\n","        t0 = time.time()\n","        for ep in range(epoch+1):\n","            ep_loss = self.grad_desc()\n","            if ep % self.info_freq ==0:\n","                elps = time.time() -t0\n","                self.ep_log.append(ep)\n","                self.loss_log.append(ep_loss)\n","                print(\"ep: %d, loss: %.3e, elps: %.3f\" % (ep, ep_loss, elps))\n","                t0 = time.time()\n","            if ep_loss \u003c tol:\n","                print(\"\u003e\u003e\u003e\u003e\u003e end time:\", datetime.datetime.now())\n","                break\n","        print(\"\u003e\u003e\u003e\u003e\u003e end time:\", datetime.datetime.now())\n","\n","    def predict(self,t,x):\n","        t = tf.convert_to_tensor(t,dtype=self.data_type)\n","        x = tf.convert_to_tensor(x,dtype=self.data_type)\n","        with tf.GradientTape(persistent=True) as tp:\n","            tp.watch(t)\n","            tp.watch(x)\n","            u = self.dnn(tf.concat([t,x],1))\n","            u_t = tp.gradient(u,t)\n","            u_x = tp.gradient(u,x)\n","        u_xx = tp.gradient(u_x,x)\n","        gv = u_t + u * u_x - self.nu * u_xx\n","        return u,gv"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1657728113060,"user":{"displayName":"Zihua Cai","userId":"13643425498526697447"},"user_tz":-480},"id":"ZNuIed9KSm5q","outputId":"7a2b7dc4-530a-43aa-bbb0-6b1d54658c00"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003e\u003e\u003e\u003e\u003e start time: 2022-07-13 16:01:51.225517\n","\u003e\u003e\u003e\u003e\u003e configuration;\n","         dtype        : \u003cdtype: 'float32'\u003e\n","         activ func   : tanh\n","         weight init  : glorot_normal\n","         learning rate: \u003ckeras.optimizer_v2.learning_rate_schedule.CosineDecay object at 0x7fdaeec68810\u003e\n","         optimizer    : Adam\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 20)                60        \n","                                                                 \n"," dense_1 (Dense)             (None, 20)                420       \n","                                                                 \n"," dense_2 (Dense)             (None, 20)                420       \n","                                                                 \n"," dense_3 (Dense)             (None, 20)                420       \n","                                                                 \n"," dense_4 (Dense)             (None, 20)                420       \n","                                                                 \n"," dense_5 (Dense)             (None, 20)                420       \n","                                                                 \n"," dense_6 (Dense)             (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 2,181\n","Trainable params: 2,181\n","Non-trainable params: 0\n","_________________________________________________________________\n","         summary      : None\n"]}],"source":["pinn = PINN(t,x,u,t_r,x_r,lb,ub,\n","            in_dim,out_dim,width,depth,\n","            activ=act,w_init=w_init,b_init=b_init,\n","            lr=lr,opt=opt,weight_data=weight_data,weight_pde=weight_pde,\n","            info_freq=info_freq,info_seed=info_seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ZJvDc4r1Sm5r"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003e\u003e\u003e\u003e\u003e training setting;\n","         # of epoch     : 8000\n","         convergence tol: 1e-08\n","WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n","ep: 0, loss: 3.361e-01, elps: 3.753\n","ep: 500, loss: 5.265e-02, elps: 12.618\n","ep: 1000, loss: 3.463e-02, elps: 11.811\n","ep: 1500, loss: 7.654e-02, elps: 9.426\n","ep: 2000, loss: 4.564e-02, elps: 6.321\n","ep: 2500, loss: 2.248e-02, elps: 6.291\n","ep: 3000, loss: 1.282e-02, elps: 6.289\n"]}],"source":["pinn.train(epoch,tol)"]},{"cell_type":"markdown","metadata":{"id":"yeojqFasSm5s"},"source":["### Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5HzbPh5GSm5s"},"outputs":[],"source":["def plot_loss(x,y,title,savepath=\"./pics\"):\n","    # plt.figure(figsize=(8,4))\n","    fig1,ax1 = plt.subplots(1)\n","    ax1.plot(x,y)\n","    ax1.grid(alpha=0.5)\n","    ax1.set_ylabel(\"loss\")\n","    ax1.set_xlabel(\"epoch\")\n","    ax1.set_title(\"train loss\")\n","\n","    # plt.figure(figsize=(8,4))\n","    fig2,ax2 = plt.subplots(1)\n","    ax2.plot(x,y)\n","    ax2.grid(alpha=0.5)\n","    ax2.set_ylabel(\"loss\")\n","    ax2.set_xlabel(\"epoch\")\n","    ax2.set_title(\"train loss(log)\")\n","\n","    # plt.figure(figsize=(8,4))\n","    fig3,ax3 = plt.subplots(1)\n","    strt = int(len(x)*0.7)\n","    ax3.plot(x[strt:],y[strt:])\n","    ax3.grid(alpha=0.5)\n","    ax3.set_xlabel(\"epoch\")\n","    ax3.set_ylabel(\"loss\")\n","    ax2.set_yscale(\"log\")\n","    ax3.set_title(\"train loss(part)\")\n","\n","    if not os.path.exists(savepath):\n","        os.makedirs(savepath)\n","    fig1.savefig(savepath+\"/\"+title)\n","    fig2.savefig(savepath+\"/\"+title+\"(log)\")\n","    fig3.savefig(savepath+\"/\"+title+\"(part\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZloS30_cSm5s"},"outputs":[],"source":["plot_loss(pinn.ep_log,pinn.loss_log,\"loss\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XyoAyJGuSm5t"},"outputs":[],"source":["def plot_solution(X,u,title,savepath=\"./pics\"):\n","    lb = X.min(0)\n","    ub = X.max(0)\n","    x = np.linspace(lb[0],ub[0],200)\n","    y = np.linspace(lb[1],ub[1],200)\n","    x,y = np.meshgrid(x,y)\n","    phi = griddata(X,u.flatten(),(x,y),method=\"linear\")\n","    plt.imshow(phi,interpolation='nearest',cmap='rainbow',extent=[0,1,-1,1],origin=\"lower\",aspect=\"auto\")\n","    plt.colorbar()\n","    plt.title(title)\n","    plt.xlabel('t')\n","    plt.ylabel('x')\n","    if not os.path.exists(savepath):\n","        os.makedirs(savepath)\n","    plt.savefig(savepath+'/'+title)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Qx_OPoVSm5t"},"outputs":[],"source":["t = np.linspace(tmin,tmax,1001)\n","x = np.linspace(xmin,xmax,101)\n","\n","t,x = np.meshgrid(t,x)\n","t = t.reshape(-1, 1)\n","x = x.reshape(-1, 1)\n","TX = np.c_[t,x]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zLQd2xnVSm5t"},"outputs":[],"source":["u_hat,r_hat = pinn.predict(t,x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SLR7wpBSm5u"},"outputs":[],"source":["plot_solution(TX, u_hat.numpy(),title='u_prediction')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sn5bstwjSm5u"},"outputs":[],"source":["plot_solution(TX, r_hat.numpy(),title='loss')"]}],"metadata":{"colab":{"name":"burgers.ipynb","version":""},"kernelspec":{"display_name":"Python 3.9.13 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"6ca3aa8ecd0b7bddf142c4852696022db00ef254c6fe98093bb8bf9134bdc29e"}}},"nbformat":4,"nbformat_minor":0}